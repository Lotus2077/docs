---
title: "系统架构指南"
description: "三单元异构系统架构的完整技术参考，包括推理单元、应用单元和硬件控制单元配置"
icon: "sitemap"
---


## 架构概览

我们的系统由三个专门的单元组成，它们协同工作以提供完整的AI基础设施解决方案：

<CardGroup cols={3}>
<Card icon="microchip" title="推理单元">
**IP地址:** 10.10.99.98  
**端口范围:** 58000-58999  
**功能:** 运行推理框架和AI模型，为AI推理负载提供计算服务。
</Card>

<Card icon="browser" title="应用单元">
**IP地址:** 10.10.99.99  
**端口范围:** 59000-59299  
**功能:** 托管用户应用程序和系统平台，管理应用程序生命周期和部署。
</Card>

<Card title="硬件控制单元" icon="monitor-waveform">
**IP地址:** 10.10.99.97  
**端口:** 80 (监控服务)  
**功能:** 提供硬件监控、配置和矩阵显示管理。
</Card>
</CardGroup>

## 计算单元配置

<Tip>
推理核心作为核心引擎，处理所有AI推理任务和模型操作。正确的配置可确保您的大语言模型推理任务获得最佳性能。
</Tip>

### 推理框架设置

计算单元同时运行多个推理框架：

- **vLLM推理框架**
  - 服务: 大语言模型(LLM)处理
  - 端口: 58000
  - 用途: 高性能LLM推理

- **TEI嵌入模型**
  - 端口: 58080
  - 用途: 文本嵌入生成

- **TEI重排序模型**
  - 端口: 58081
  - 用途: 搜索结果重排序

### 模型存储配置

<Tabs>
<Tab title="手动模型存储">
存储您手动配置和部署的模型：

```bash
~/cfe/model/
├── llm/          # 大语言模型
├── embedding/    # 嵌入模型
└── reranker/     # 重排序模型
```

<Note>
将需要自定义配置或手动部署流程的模型存储在此目录中。
</Note>
</Tab>

<Tab title="自动启动模型存储">
存储随系统自动启动的模型：

```bash
~/cfe/autoModel/
├── llm/          # 大语言模型
├── embedding/    # 嵌入模型
└── reranker/     # 重排序模型
```

<Tip>
此目录中的模型将根据自动启动配置在系统启动时自动加载。
</Tip>
</Tab>
</Tabs>

### 自动启动配置

配置自动模型启动行为：

**配置文件:** `~/cfe/autorun.sh`

<Note>
此脚本可由用户编辑且未加密。您可以修改它以指定系统启动时应自动启动哪些模型。
</Note>

```bash ~/cfe/autorun.sh
#!/bin/bash
# 计算单元的自动启动配置
# 指定要自动启动的默认模型

# 示例: 启动LLM模型
./start_llm_model.sh

# 示例: 启动嵌入模型
./start_embedding_model.sh
```

## 应用单元配置

<Tip>
应用单元为用户应用程序和系统平台提供灵活的部署环境。它包括Web服务功能和专门的AI平台。
</Tip>

### 核心服务

**Nginx Web服务器**
- 端口: 80
- 用途: 服务用户应用程序并处理HTTP请求
- 配置: 具有反向代理功能的标准nginx设置

**系统平台**
- **Dify平台**
  - 端口: 59080
  - 用途: AI应用程序开发平台
  - 功能: 工作流构建器、模型管理、API端点

- **Altai (本地部署)**
  - 端口: 59299
  - 用途: 本地AI部署和管理
  - 功能: 自托管AI模型服务

### 应用程序存储结构

<Tabs>
<Tab title="导入应用程序存储">
部署前导入应用程序的位置：

```bash
~/cfe/app/    # 未加密的导入应用程序
```

<Warning>
此目录中的应用程序未加密。在导入敏感应用程序之前，请确保采取适当的安全措施。
</Warning>
</Tab>

<Tab title="运行时应用程序存储">
活动应用程序部署位置：

```bash
~/app/        # 运行时应用程序 (在NVMe SSD上)
```

<Note>
此目录位于应用单元的NVMe SSD上，以在运行时获得最佳性能。
</Note>
</Tab>
</Tabs>

## 硬件控制单元配置

<Tip>
硬件控制单元提供全面的监控和配置功能。它确保系统稳定性并允许自定义硬件显示。
</Tip>

### 监控服务

**硬件监控前端**
- 路径: `/sdcard/web`
- 端口: 80
- 用途: 基于Web的硬件监控界面

<Note>
监控前端可由用户修改。您可以通过编辑`/sdcard/web`目录中的文件来自定义界面。
</Note>

### 显示配置

**矩阵显示设置**
- 配置文件: `/sdcard/matrix.json`
- 用途: 配置矩阵显示标志和图案

```json /sdcard/matrix.json
{
  "logo": "custom_logo.png",
  "brightness": 80,
  "animation": "fade",
  "duration": 5000
}
```

## 设置和配置步骤

<Steps>
<Step title="验证网络配置">
确保所有三个单元可以相互通信：

```bash
# 测试计算单元连接
ping 10.10.99.98

# 测试应用单元连接  
ping 10.10.99.99

# 测试硬件控制单元连接
ping 10.10.99.97
```

<Check>
所有单元应在本地网络内响应ping请求。
</Check>
</Step>

<Step title="配置端口访问">
验证所需端口可用且未被防火墙阻止：

- 计算单元: 端口 58000-58999
- 应用单元: 端口 59000-59299
- 硬件控制单元: 端口 80

<Warning>
确保与网络上运行的其他服务没有端口冲突。
</Warning>
</Step>

<Step title="设置模型存储">
在计算单元上创建所需的目录结构：

```bash
# 创建手动模型目录
mkdir -p ~/cfe/model/{llm,embedding,reranker}

# 创建自动启动模型目录
mkdir -p ~/cfe/autoModel/{llm,embedding,reranker}
```

<Check>
验证目录已创建并具有适当的模型存储权限。
</Check>
</Step>

<Step title="配置自动启动脚本">
编辑自动启动配置：

```bash
# 编辑自动启动脚本
nano ~/cfe/autorun.sh

# 使其可执行
chmod +x ~/cfe/autorun.sh
```

<Tip>
在依赖自动启动之前，手动测试您的自动启动脚本。
</Tip>
</Step>

<Step title="部署应用程序">
在应用单元上设置应用程序存储：

```bash
# 创建应用程序目录
mkdir -p ~/cfe/app
mkdir -p ~/app

# 设置适当的权限
chmod 755 ~/cfe/app ~/app
```

<Check>
验证应用程序可以部署并通过配置的端口访问。
</Check>
</Step>
</Steps>

## 安全注意事项

<Warning>
**重要安全说明:**
- 所有导入的应用程序和脚本都以未加密格式存储
- 自动启动脚本可由用户编辑且未加密
- 确保为敏感操作设置适当的访问控制
- 定期更新和监控所有系统组件
</Warning>

## 故障排除

<AccordionGroup>
<Accordion icon="ethernet" title="端口连接问题">
**常见问题:**
- 防火墙阻止配置的端口
- 单元之间的网络连接问题
- 与现有服务的端口冲突

**解决方案:**
- 检查所需端口范围的防火墙规则
- 使用ping测试验证网络连接
- 使用`netstat`识别端口冲突
</Accordion>

<Accordion icon="brain" title="模型加载失败">
**常见问题:**
- 模型目录路径不正确
- 模型文件权限不足
- 自动启动脚本配置错误

**解决方案:**
- 验证模型文件位于正确的目录中
- 使用`ls -la`检查文件权限
- 手动测试自动启动脚本
</Accordion>

<Accordion icon="docker" title="应用程序部署问题">
**常见问题:**
- 应用程序存储路径配置
- NVMe SSD访问问题
- 端口分配冲突

**解决方案:**
- 验证存储路径存在且可访问
- 检查NVMe SSD挂载状态
- 审查端口分配是否有冲突
</Accordion>
</AccordionGroup>

## 后续步骤

完成系统设置后：

1. **部署您的第一个模型**: 将模型上传到计算单元并测试推理
2. **配置应用程序**: 在应用单元上设置您的第一个应用程序
3. **监控系统健康状况**: 使用硬件控制单元监控系统性能
4. **自定义显示**: 为您的环境配置矩阵显示设置

<Note>
如需额外的技术支持或高级配置指导，请联系您的系统管理员或参考详细的API文档。
</Note>

---

<div className="text-center text-sm text-gray-500 mt-8">
  © 2025 泛灵（成都）人工智能科技有限公司 版权所有
</div>
