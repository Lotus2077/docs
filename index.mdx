---
title: "Introduction"
description: "Welcome to the RM-01 AI Supercomputer Documentation - your comprehensive guide to deploying and managing enterprise AI solutions"
---

<iframe className="w-full aspect-video rounded-xl" src="https://www.youtube.com/embed/qEKqEdGf9o8?si=34GlLpjV77RF_thm" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen />

## What is RM-01?

The RM-01 is a state-of-the-art portable AI supercomputer designed for private, on-premises deployment of large language models and AI applications. Built for enterprise environments, it delivers powerful AI capabilities while maintaining complete data sovereignty and security.

### Key Capabilities

<CardGroup cols={2}>
    <Card title="High-Performance Local Inferencing" icon="rocket">
        Up to 2070 TFLOPS (FP4) computing power with 32/64/128GB GPU memory for efficient local AI inference
    </Card>
    <Card title="One-stop Shop for Enterprise AI" icon="sd-card">
        Dedicated 24GB RAM for AI applications and 8TB SSD for RAG data storage
    </Card>
    <Card title="Enterprise Security" icon="shield">
        Hardware-level asymmetrical encryption and secure key management providing fully private, on-premises operation with no data leaving your device
    </Card>
    <Card title="Lightweight Deployment" icon="feather">
        0 cost for deployment, maintenance and a flat learning curve making it the most cost-effective local AI solution for enterprises
    </Card>
</CardGroup>

## Core Features

### High-Performance Local Inferencing with Flexible Model Support


<Tabs>
<Tab title="Model Range">
    **Supported Model Sizes and Types:**
    - 0.5B to 235B parameters (GPTQ Int4 quantization)
    - Mainstream open-source models (DeepSeek, Qwen, Llama)
    - Custom enterprise/industry-specific models
    - Support for multi-modal models
</Tab>
<Tab title="Performance">
    **Inference Capabilities:**
    - Concurrent multi-model support
    - Multi-user support
    - Hardware-accelerated inference with total throughput of over 2000 TPS (tokens per second)
</Tab>
<Tab title="Deployment">
    **Deployment Guarantees:**
    - Plug-and-play installation
    - Real-time model switching
    - Zero-maintenance design
    - Enterprise integration ready
  </Tab>
</Tabs>

### One-stop Solution for Enterprise AI
<Tabs>
    <Tab title="AI Applications First">
        - 24GB dedicated RAM for AI applications
        - Managing and deploying AI applications with Docker
        - Asymmetrical hardware-level encryption for safe application delivery
    </Tab>
    <Tab title="RAG Ready">
        - Embedding model automatically loaded and ready for RAG applications
        - Reranker model automatically loaded and ready for RAG applications
        - Vector database automatically loaded and ready for RAG applications
        - 8TB SSD for data storage
    </Tab>
    <Tab title="Maximum Compatibility">
        - One USB-C port for connection to any device
        - RM-01 will be recognized as a network device
        - Use and manage AI applications/models with assigned local IP addresses and APIs
        - Could be used as a server with a USB-C to Ethernet adapter
    </Tab>
</Tabs>

### Enterprise-Grade Security & Privacy

<Steps>
  <Step title="Data Sovereignty">
    All data processing occurs locally on your device. No information is transmitted to external servers or cloud services.
</Step>
<Step title="Hardware Encryption">
    Built-in hardware-level encryption ensures your data remains secure at all times, even the device is lost or stolen.
</Step>
<Step title="Access Control">
    Enterprise-grade user authentication and authorization systems protect against unauthorized access.
  </Step>
  <Step title="Compliance Ready">
    Meets industry standards for data protection and privacy regulations including GDPR, HIPAA, and SOC 2.
  </Step>
</Steps>

### Lightweight Deployment for Low Enterprise TCO

<Tabs>
    <Tab title="Deployment Cost">
        - One-click deployment within 300 seconds with 0 cost
        - No dedicated IT staff required
        - Not intrusive to existing IT infrastructure
    </Tab>
    <Tab title="Maintenance Cost">
        - Extremely stable and reliable with 0 maintenance required
        - Power off and on to recover from any unexpected issues
        - No dedicated maintenance staff required
    </Tab>
    <Tab title="Learning Curve">
        - Flat learning curve for enterprise users with no need to learn complex AI technologies
        - Card swapping with one-touch deployment for any AI solutions
    </Tab>
</Tabs>

## What's Next?

Choose your path based on your role and requirements:

<CardGroup cols={3}>
  <Card title="Enterprise Quickstart" icon="play" href="quickstart">
    **For Enterprise Users**

    Get started with your RM-01 device, including hardware setup, management interface access, and using AI applications.
  </Card>
  <Card title="Vendor Deployment Guide" icon="server" href="essentials/deploy">
    **For Vendors & Service Providers**

    Complete deployment guide for implementing RM-01 in enterprise environments, including model preparation and system integration.
  </Card>
  <Card title="System Architecture Guide" icon="sitemap" href="essentials/develop">
    **For Developers**

    Technical guide for building applications on RM-01, covering system architecture, environment setup, and model integration.
  </Card>
</CardGroup>

---

<div className="text-center text-sm text-gray-500 mt-8">
Â© 2025 Panidea (Chengdu) Artificial Intelligence Technology Co., Ltd. All rights reserved.

</div>