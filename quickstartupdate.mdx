# RM-01 快速入门指南

欢迎体验 RM-01，这款强大又易用的便携 AI 超算！本指南将帮助您快速上手，无论您是新手还是有经验的用户，我们都会用简单的方式带您完成设置和初步使用。

RM-01 由三个核心部件组成：**推理模组**、**应用模组** 和 **带外管理芯片**（简称管理模组）。它们通过内置的以太网交换芯片连接，形成一个内部局域网。当您通过 **USB Type-C** 线连接 RM-01 到主机（如电脑、手机或平板）时，设备会自动为您的主机分配一个网络接口，加入 RM-01 的网络，实现数据交互。

---

## 第一步：连接与网络设置

1. **连接设备**  
   使用 **USB Type-C** 线将 RM-01 连接到您的主机（PC、手机或平板）。设备上电后，会自动配置内部网络，您的主机将被分配静态 IP 地址：**10.10.99.100**。  
   - RM-01 的其他部件 IP 地址如下：
     - **管理模组**：`10.10.99.97`
     - **推理模组**：`10.10.99.98`
     - **应用模组**：`10.10.99.99`

2. **启用互联网共享（可选）**  
   如果您希望 RM-01 访问互联网，可以通过主机共享网络。以 macOS 为例：  
   - 打开 **系统设置** > **网络** > **共享**。  
   - 启用 **互联网共享**，选择 **Wi-Fi** 作为共享来源。  
   - 在“共享给设备”中，勾选 RM-01 的网络接口（显示为 **AX88179A** 或 **RMinte RM-01**，视版本而定）。  
   - 手动设置 RM-01 网络接口：  
     - **IP 地址**：`10.10.99.100`  
     - **子网掩码**：`255.255.255.0`  
     - **路由器**：`10.10.99.100`（即主机自身 IP）  
   - 点击 **完成**，您的 RM-01 即可通过主机访问互联网！

> **小提示**：此设置让您的主机充当网关，RM-01 会自动获取默认网关和 DNS。如果您不需互联网访问，可跳过此步。

---

## 第二步：探索核心功能

### 1. 实时监控（管理模组）  
管理模组内置了 **RobOS** 实时性能监控面板。您可以通过浏览器访问 `http://10.10.99.97`，查看 RM-01 各模组的连接状态和运行情况。  
- 这是一个方便的工具，让您随时掌握设备的健康状态！

### 2. 快速调试（应用模组）  
应用模组预装了 **Open WebUI**，方便您进行模型调试和对话测试。只需在浏览器中访问 `http://10.10.99.99`，即可开始体验！  
- **默认登录信息**：  
  - 用户名：`rm01`  
  - 密码：`rm01`  
  - **重要**：首次登录后，请使用 SSH 登录（地址：`10.10.99.99`）并更改密码，以确保安全。  
- 如果您购买或部署了其他应用，它们也运行在应用模组（`10.10.99.99`）上。具体端口号或使用方式，请联系您的经销商。

---

## 第三步：加载开源模型（自动模式）

RM-01 支持快速加载开源大语言模型（LLM），让您轻松验证模型兼容性。以下是步骤：

1. **准备模型文件**  
   使用 **CFexpress Type-B** 读卡器，将模型的完整权重文件（支持 `.safetensors`、`.bin`、`.pt`、`.awq` 等格式）放入存储卡的 `auto/llm/` 目录。  
   - **正确示例**：  
     ```
     auto/llm/model-001-of-006.safetensors
     auto/llm/config.json
     auto/llm/tokenizer.json
     auto/llm/vocab.json
     ```  
   - **错误示例**（不要使用子文件夹）：  
     ```
     auto/llm/Qwen3-30B-A3B-Instruct-2507-AWQ/model.safetensors
     ```

2. **插入存储卡并启动**  
   将 **CFexpress Type-B** 存储卡插入 RM-01，重新启动设备。系统会自动扫描 `auto/llm/` 目录并加载兼容的模型。

3. **访问推理服务**  
   模型加载完成后，您可以通过以下地址访问推理服务：  
   - **地址**：`http://10.10.99.98:58000/v1/chat/completions`  
   - 支持标准 OpenAI 客户端（如 `openai-python`、Postman 或 curl）调用。

> **注意**：  
> - 自动模式仅支持大语言模型（LLM），不支持嵌入模型（embedding）或重排序模型（reranker）。  
> - 自动模式适合快速验证模型兼容性，性能会受限（最大上下文长度 ≤ 8192 tokens，显存使用率 ≤ 0.8）。  
> - 如果您需要更高性能或多模型部署，请联系经销商获取 **手动模式（dev）** 的技术支持。

---

## 安全与使用须知

- **不要直接访问推理模组**：推理模组不支持 SSH 登录，所有模型管理需通过 **CFexpress Type-B** 存储卡完成。  
- **备份模型文件**：在更新模型前，建议备份存储卡中的 `auto/` 和 `dev/` 目录，以防配置丢失。  
- **联系支持**：如需更高级的配置（如手动模式、多模型并行）或遇到问题，请联系您的经销商获取专业支持。

---

## 下一步

恭喜您成功入门 RM-01！您可以：
- 通过 `http://10.10.99.97` 监控设备状态。
- 访问 `http://10.10.99.99` 使用 Open WebUI 进行模型调试。
- 尝试加载自己的开源模型到 `auto/llm/` 目录，体验 AI 推理的乐趣！

如果您想深入开发或优化 RM-01 的性能，请参考《RM-01 开发者使用指南》或联系经销商获取更多支持。祝您使用愉快！